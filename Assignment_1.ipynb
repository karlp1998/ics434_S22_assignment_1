{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview \n",
    "\n",
    "* In this assignment, you will practice some data wrangling functionality commonly used in real-world projects.\n",
    "\n",
    "* This assignment is designed around two dataset\n",
    "\n",
    "* The Medicaid Data per State  \n",
    "\n",
    "* IRS Statistics of Income (SOI) dataset\n",
    "\n",
    "\n",
    "* The final product of this assignment will be a table with medication cost per Medicaid enrollee per state. This dataset will allow us to answer such questions as:\n",
    "  * Which medications account for the bulk of a state's spending   \n",
    "  * Which medications are prescribed more frequently in one state than another.\n",
    "  * etc.\n",
    "\n",
    "* The following URLs provide the datasets required for this assignment:\n",
    "  * [medicaid_data.csv](https://www.dropbox.com/s/u6ctjqxnk0wxpbk/medicaid_data.csv?dl=1)\n",
    "  * [medicaid_enrollment.tsv](https://www.dropbox.com/s/969mohzhpu78r10/medicaid_enrollment.tsv?dl=1)\n",
    "  * [tax_data.csv](https://www.dropbox.com/s/zm37nu7vnirha4m/tax_data.csv?dl=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Instructions on answering the questions\n",
    "\n",
    "- Some of the questions below require that you only use methods or properties of a `DataFrame` or a `Series`. Therefore, any solution that uses a function that is not a method or property of `DataFrame` or `Series` will not be accepted, even when the solution yields an appropriate answer to the question.\n",
    "\n",
    "- For instance, if you are asked to find the number of entries in the DataFrame `tax_data ` using only the DataFrame's methods or properties, then `len(tax_data)` is not an acceptable solution since `len()` is not a `tax_data` method. The statements below are both correct answers:\n",
    "\n",
    "  - `info()` is a method `tax_data`\n",
    "  \n",
    "```python\n",
    "   \n",
    "    tax_data.info()\n",
    "```\n",
    "\n",
    "  or\n",
    "\n",
    "  - `shape` is a property of `tax_data`\n",
    "\n",
    "\n",
    "```python\n",
    "tax_data.shape\n",
    "```\n",
    "\n",
    "- Similarly, if you are asked to find to count the number of unique entries in the `STATEFIPS` column of the `tax_data` DataFrame, then solutions using set() or len() are not acceptable for the following reasons:\n",
    "\n",
    "- The solution below uses `set()` and `len()`, which are not `tax_data` methods\n",
    "\n",
    "```python\n",
    "len(set(tax_data[\"STATEFIPS\"]))\n",
    "```\n",
    "\n",
    "- The solution below uses `unique()`, which is a  `tax_data` method, but then counts the number of uniques entries using `len()` which is not `tax_data` method\n",
    "\n",
    "```python\n",
    "len(tax_data[\"STATEFIPS\"].unique())\n",
    "```\n",
    "\n",
    "\n",
    "- The statement below is an acceptable solution since it uses `nunique()` which is a method of the `Series` generated by indexing on a column of `tax_data` (`tax_data['STATEFIPS'])\n",
    "\n",
    "```python\n",
    "tax_data['STATEFIPS'].nunique()\n",
    "```\n",
    "\n",
    "\n",
    "- Chaining methods and properties is encouraged if it does not cause ambiguity \n",
    "\n",
    "- For instance, to identify whether a value is part of the index, write the following:\n",
    "\n",
    "```python\n",
    "tax_data.index.contains(99999)\n",
    "```\n",
    "\n",
    "- Rather than:\n",
    "\n",
    "```python\n",
    "9999 in tax_data.index\n",
    "```\n",
    "\n",
    "- You can only import `pandas` and `numpy`\n",
    "\n",
    "- If you are not explicitly asked to only use methods or properties of a `DataFrame` or a `Series`, then any solution that does not rely on external modules will be accepted.\n",
    "\n",
    "- __Important__: Provide the exact statement(s) used to answer each question\n",
    "\n",
    "- Unless otherwise specified, each cell can contain multiple lines of code\n",
    "\n",
    "* Finally, note that not all the functions necessary for answering the questions below were covered in class. As such, assuming you are using Jupyter Notebooks, I suggest you use `.SHIFT+TAB` on objects liberally to see which methods and properties are available on objects. If you are unsure what a method does, use `SHIFT+TAB` twice to invoke the `docstring`, or documentation for that function. This is not only a good way to see which functionality can be used to answer the questions below but also a great way to familiarize yourself with the plethora of functionality available through the `pandas` package. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and exploring the tax data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas and numpy using their appropriate alias here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Load the IRS Statistics of Income (SOI) dataset (`tax_data.csv`) into a `DataFrame` called `tax_data`. This file can be downloaded from the `URL` provided above.\n",
    "\n",
    "* This file `tax_data.csv` was preprocessed from the original file I obtained at the following URL:\n",
    "  * [15zpallagi.csv](https://www.irs.gov/pub/irs-soi/15zpallagi.csv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use a `tax_data` method or property to display the first eight (8) rows of the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Modify `tax_data` to uppercase all the header names. \n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "  * Do not hardcode the operation by uppercasing the columns yourself\n",
    "  *  You can use `tax_data.columns`, which returns a `Series` of the column names.\n",
    "\n",
    "* The resulting column name should look as follows:\n",
    "\n",
    "```\n",
    "STATEFIPS    STATE    ZIPCODE    AGI_STUB    N1    MARS1    MARS2    MARS4    PREP    N2    ...    \n",
    "```\n",
    "\n",
    "* Standardizing column names is a good way to avoid having to guess whether the column header is in lowercase or uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the total number of entries (also called observations or instances) in `tax_data` dataset?\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If `STATEFIPS` is the header label of the first column in `tax_data`, write code to print the title of the 32nd column.  \n",
    "  * You should use a single python expression\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If `STATEFIPS` is the first column label (index 0), what is the index of the column labeled `N10300`?\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the count of unique zip codes in each state using descending order.\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "\n",
    "- The result should look like the following ( '...' represents remaining data that is not shown here)\n",
    "```python\n",
    "\n",
    "        ZIPCODE\n",
    "STATE\t\n",
    "TX\t     9714\n",
    "NY\t     9238\n",
    "CA\t     8908\n",
    "PA\t     8208\n",
    "IL\t     7386\n",
    "...\n",
    "```\n",
    "\n",
    "* The above indicates that there are 9,714 unique zip codes in TX, 9,238 in NY, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Identify the position of `HI` in the list of zip code counts per state generated in the previous question\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identifying and Removing Ambiguous Zip Codes\n",
    "\n",
    "- Count the number of entries where ZIPCODE is 0, assign your results to a variable named  `nb_invalid_zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line in the code cell below to make sure that `nb_invalid_zip` is an integer (`int`)\n",
    "  * Note that `assert` will only print an error if `type(nb_invalid_zip)` is not of type `int`\n",
    "* If the code cell below returns an error, then change your answer above so that the value returned is a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(type(nb_invalid_zip) == int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove from `tax_data` all the instances where the zip code is `0` and save the resulting `DataFrame` to a variable named `tax_data_valid_zip`\n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line below to confirm that the operation worked as expected\n",
    "\n",
    "  * The assertion below verifies that the number of lines with \"zip code equal to  0\" + number of lines in `tax_data_valid_zip` is equal to the number of lines in the original `DataFrame` `tax_data`\n",
    "  \n",
    "  * The assertion below will fail (and print an error message) if the results do not match. If that is the case, please review your code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert((tax_data_valid_zip.shape[0] + nb_invalid_zip) == tax_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying and Removing Lines with Missing Values\n",
    "\n",
    "* How many lines contain at least one missing value `NaN` in the `tax_data_valid_zip` `DataFrame`?\n",
    "  * Your answer can only use `DataFrame` methods and properties\n",
    "* Assing the count of `NaN` into a variable called nb_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a new `DataFrame` containing all the lines from `tax_data_valid_zip`, except lines containing missing values (`NaN`)\n",
    "\n",
    "* Call the new `DataFrame` `tax_data_valid_zip_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line below to confirm that the operation worked as expected. The assertion below tests that:  \n",
    "`nb_missing_values` + number of lines in `tax_data_valid_zip_cleaned` is equal to the number of lines in `tax_data_valid_zip`\n",
    "  \n",
    "* Note that assert will only print an error if the results do not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert((tax_data_valid_zip_cleaned.shape[0] + nb_missing_values) == tax_data_valid_zip.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Percentile Income per Zip Code\n",
    "* The function `compute_percentile_zipcode` below computes the percentile income per zip code\n",
    "* By default `percentile=0.5`, i.e., the function computes the median\n",
    "* Read the code and make sure you understand what it does before moving on to the next question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_percentile_zip(df_zip, percentile=0.5):     \n",
    "    index_median = sum(( df_zip[\"N1\"]/ sum(df_zip[\"N1\"])).cumsum() <= percentile)\n",
    "    val_below_or_at_median = (df_zip[\"A00100\"] /df_zip[\"N1\"]).iloc[index_median]\n",
    "    return val_below_or_at_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the 65th income percentile ( percentile=0.65) for each zip code in `tax_data_valid_zip_cleaned` data frame\n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "  \n",
    "  * You can use any of the submethods discussed in the Split-Apply-Combine paradigm.\n",
    "  \n",
    "* Sort the values in descending order and assign them to a new `DataFrame` called `zip_rev_all`\n",
    "\n",
    "* The resulting `Series` should look like the following ( '...' represents remaining data that is not shown)\n",
    "\n",
    "```Python\n",
    "ZIPCODE\n",
    "33109    3954.114286\n",
    "33480    3413.301538\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What are the three zip codes with the most significant 65th percentile value for income?\n",
    " * I.e., the top three zip codes in your sorted listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Working with the Medicaid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and exploring the data \n",
    "\n",
    "* Load the Medicaid data stored in the file `medicaid_data.csv` into a `DataFrame` called `medicaid_data`. The file can be downloaded from the URL provided above. \n",
    "* Note that this is quite large and may take some time to load on a computer with modest RAM resources (e.g., less than 6-8 GB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify `medicaid_data` to capitalize all column names \n",
    "\n",
    "  * If your solution uses an assignment, the righthand side of the assignment (rvalue) can only use `DataFrame` or `Series` methods or properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Familiarize yourself with the data\n",
    "  * the `NDC` column stands for National Drug Code, a universal product identifier for human drugs in the United States\n",
    "  * The remaining column names are self-explanatory\n",
    "* Explore the number of lines and columns in the data\n",
    "* Check that your column headers are capitalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you explore the `LOCATION` column for all the entries for which \"STATE\" value is equal to \"HI\" you'll notice that all the values are identical.\n",
    "* Are there any states that have more than one value for `LOCATION`. \n",
    "  * This question can be answered by using aggregation and the Split-Apply-Combine paradigm\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To compare medication prescriptions across states in a fair and balanced way, we need the number of Medicaid beneficiaries in each state.  That is, we need to compare per capita. The following example illustrates the importance of normalizing the values `UNITS REIMBURSED` for each medication in each state by the number of Medicaid enrollees in each state.\n",
    "\n",
    " \n",
    "* The `medicaid_data` DataFrame shows that for the drug with NDC `61958180101` (the drug name is HARVONI and it's used to treat Hepatitis C) there were 11,886  units sold in KY, versus 40,142 in CA -- that's almost 4 times more units sold in CA compared to KY. However, there are 1,284,193 Medicaid enrollees in KY, versus 13,096,861 in California. If we normalize the number of units sold in KY, versus CA, we find that the normalized there were close to 3 times more HARVONI prescriptions in KY  than in CA. This is ___perhaps___ justified by the fact the KY has one of the highest rates of reported cases of Hepatitis C in the US (2.7% in KY versus 0.2% in CA).\n",
    "\n",
    "\n",
    "https://www.cdc.gov/hepatitis/statistics/2015surveillance/pdfs/2015hepsurveillancerpt.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of enrollees per state was obtained [here](https://www.medicaid.gov/medicaid/managed-care/enrollment/index.html)\n",
    "\n",
    "* A parsed/processed version (`medicaid_enrollment.tsv`) can be downloaded from the URL provided above. Use `pandas` to load the `medicaid_enrollment.tsv` file into DataFrame named `medicaid_enrollment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify `medicaid_enrollment` `DataFrame` to capitalize all the column names \n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "  * Do not hardcode the operation by manually uppercasing the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that some states/territories have missing values. Remove the missing values and save the resulting `DataFrame` as a new variable named `medicaid_enrollment_cleaned`\n",
    "* Pay attention to how 'n/a' is given here!\n",
    "* After cleaning, do you still have the Guam entry? If so, reconsider what missing value means in this context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting `TOTAL MEDICAID ENROLLEE` Data Type\n",
    "\n",
    "* Given that data on `TOTAL MEDICAID ENROLLEE` column contains commas on file (ex. 3,269,999 instead of 3269999), `pandas` has erroneously set the data type for that column as a string. We need to convert the column from string to `int` since we will be using it in an arithmetic expression during normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inspect the `dtype` property of \"TOTAL MEDICAID ENROLLEES\" column, and make sure that the data type is `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associating `medicaid_data` and `medicaid_enrollment_cleaned`\n",
    "\n",
    "* We can use the shared State information across both tables to associate both tables (SQL JOIN).\n",
    "\n",
    "* However, `medicaid_data` contains two-letter state abbreviations, while `medicaid_enrollment_cleaned` contains the complete state name\n",
    "\n",
    "  * We need to convert (or append) two-letter state abbreviations to `medicaid_enrollment_cleaned`\n",
    "\n",
    "* Pandas can read HTML and parse the code for tables. We will use that functionality to read in the state abbreviations from a Wikipedia page.\n",
    "\n",
    "  * A brief description of what the code does is included in the comments\n",
    "  \n",
    "* Note that the code below may throw an error if `lxml` is not installed on your machine. You should install any Python packages that Python complains about before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US STATE</th>\n",
       "      <th>POSTAL ABBREVIATION</th>\n",
       "      <th>STANDARD ABBREVIATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>Ala.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Ariz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "      <td>Ark.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>Calif.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     US STATE POSTAL ABBREVIATION STANDARD ABBREVIATION\n",
       "0     Alabama                  AL                  Ala.\n",
       "1      Alaska                  AK                Alaska\n",
       "2     Arizona                  AZ                 Ariz.\n",
       "3    Arkansas                  AR                  Ark.\n",
       "4  California                  CA                Calif."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://www.50states.com/abbreviations.htm'\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=header)\n",
    "\n",
    "tables = pd.read_html(r.text)\n",
    "\n",
    "\n",
    "# We access the desired table by giving it's index.\n",
    "# Since the URL contain only one table, then we can access that table using index 0\n",
    "Codes_abbreviations = tables[0]\n",
    "Codes_abbreviations.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the the `DataFrame`'s headers from ['US STATE',\t'POSTAL ABBREVIATION', \t'STANDARD ABBREVIATION'] to ['US STATE', 'ABBREVIATION', `STD ABBREVIATION`]\n",
    "  * You can hard code this operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combine the tables `medicaid_enrollment_cleaned` and `Codes_abbreviations` such that the resulting `DataFrame` contains all the columns in `medicaid_enrollment_cleaned` and only `ABBREVIATION` from `Codes_abbreviations` \n",
    "\n",
    "* Save the results to a variable named `medicaid_enrollment_cleaned_with_zip`\n",
    "\n",
    "* `medicaid_enrollment_cleaned_with_zip` should look like the following ( '...' represents remaining data that is not shown):\n",
    "\n",
    "\n",
    "```\n",
    "   STATE    Total Medicaid Enrollees    ABBREVIATION\n",
    "0    Alabama    1,050,989    AL\n",
    "1    Alaska    164,783    AK\n",
    "2    Arizona    1,740,520    AZ\n",
    "3    Arkansas    762,166    AR\n",
    "4    California    13,096,861    CA\n",
    "...\n",
    "```\n",
    "\n",
    "* We did not cover joins in class -- you find a plethora of examples on how to do this online (e.g., `https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html`) and in a notebook under `Data Wrangling - Advanced` module. See for instance:\n",
    "\n",
    "\n",
    "* If you cannot get it to work, contact the `TA` for the solution. You will not be penalized if you don't answer this question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have no further use for the column STATE in  `medicaid_enrollment_cleaned_with_zip`\n",
    "\n",
    "  * Remove the column and make sure the data in `medicaid_enrollment_cleaned_with_zip` looks like the following  ( `...` represents remaining data that is not shown):\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "    Total Medicaid Enrollees    ABBREVIATION\n",
    "0   1,050,989                  AL\n",
    "1   164,783                    AK\n",
    "2   1,740,520                  AZ\n",
    "3   762,166                    AR\n",
    "4   13,096,861                 CA\n",
    "....\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `DataFrame medicaid_enrollment_cleaned_with_zip` to assign the appropriate number of Medicaid enrollees to each entry in the `medicaid_data`\n",
    "\n",
    "   I.E., instead of the 10 original columns, `medicaid_data` will now have an 11th column representing the `TOTAL MEDICAID ENROLLEES` according to the STATE value in the entry.\n",
    "   \n",
    "- Save the resulting DataFrame into a new variable called `medicaid_data_w_enrollments`\n",
    "- The resulting DataFrame should look like the following (`...` represents remaining data that is not shown):\n",
    "\n",
    "```\n",
    "UTILIZATION TYPE    STATE    NDC    PRODUCT NAME    UNITS REIMBURSED    NUMBER OF PRESCRIPTIONS    TOTAL AMOUNT REIMBURSED    MEDICAID AMOUNT REIMBURSED    NON MEDICAID AMOUNT REIMBURSED    LOCATION\n",
    "0    MCOU    PA    55150023930    Dexamethas    33.0    19.0    234.98    234.98    0.0    (40.5773, -77.264)\n",
    "1    FFSU    NY    23917710    ALPHAGAN P    570.0    57.0    16006.34    16006.34    0.0    (42.1497, -74.9384)\n",
    "2    MCOU    OR    13925050501    Dapsone 10    456.0    15.0    1052.42    1052.42    0.0    (44.5672, -122.1269)\n",
    "...\n",
    "```\n",
    "\n",
    "* The order of the columns in the `DataFrame` is not relevant. This answer uses the same approach as the one used to `merge` the tables above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove any lines where \"STATE\" or \"PRODUCT NAME\" are missing from  `medicaid_data_w_enrollments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use [\"STATE\", \"PRODUCT NAME\"] as hierarchical index for `medicaid_data_w_enrollments`. Recall that a hierarchical index is simply an index with multiple levels of indexing (multiple columns)\n",
    "  * Hint: the function to set an index on a `DataFrame` can take a single column name or a list of column names. The list here is  [\"STATE\", \"NDC\"]\n",
    "- Call the new data `medicaid_data_w_enrollments_hierarch`\n",
    "- Inspect your data to make sure the new index has now two levels (STATE and NDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Write a single Pandas expression to print all the lines containing `NDC` `61958180101` in the Pennsylvania (\"PA\")\n",
    "\n",
    " * Use a single indexing call (bracket notation) using `loc`\n",
    " \n",
    " * Hint 1: Since your index is hierarchical, `loc` is expecting two values, the first for STATE and the second for NDC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the normalized `UNITS REIMBURSED` per drug \n",
    "\n",
    "\n",
    "\n",
    "* Compute the `UNITS REIMBURSED` for each \"NDC\" in each state normalized by the number of enrollees.\n",
    "\n",
    "\n",
    "\n",
    "- For instance in `PA`, the total `UNITS REIMBURSED` for the HARVONI `NDC` (61958180101) is 10,612\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "total_amount_reimbursed = medicaid_data_w_enrollments_hierarch.loc[(\"PA\", 61958180101), \"UNITS REIMBURSED\"].sum() \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- And the numebr of Medicaid Enrollees in \"PA\" is 2,569,232\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "total_enrollees_PA = medicaid_data_w_enrollments_hierarch.loc[\"PA\", \"TOTAL MEDICAID ENROLLEES\"].unique()[0]\n",
    "\n",
    "```\n",
    "\n",
    "- Therefore, the UNITS REIMBURSED per enrollee for \"HARVONI\" is  0.00413041718303\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "print(total_amount_reimbursed/total_enrollees_PA)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- Rather than work directly with the ratios, we are going to compute and work with their logarithm (np.log2) instead.\n",
    "\n",
    "\n",
    "\n",
    "  - The reason we use logs here is to avoid working small numbers. More on log-transformation in future lectures\n",
    "\n",
    "\n",
    "\n",
    "- Save the result in a `Series` called `medicaid_reimbursement_per_enrollee`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Your final result should be a `Series` that looks like the following ( `...` represents data that is not shown here):\n",
    "  * Note that negative values are the result of the `log` transformation \n",
    "\n",
    "```\n",
    "STATE  NDC    \n",
    "AK     2143380    -9.609109\n",
    "       2143480   -10.008280\n",
    "       2322730    -6.109830\n",
    "       2322830    -4.444321\n",
    "       2322930    -3.855995\n",
    "...\n",
    "AL     2143380    -9.940595\n",
    "       2143480    -9.805485\n",
    "       2322730    -5.336260\n",
    "...\n",
    "MA     2143380    -7.921997\n",
    "       2143480    -7.803463\n",
    "       2144511   -13.472194\n",
    "       2197590    -7.741402\n",
    "       2322730    -5.414724\n",
    "       2322830    -4.592154\n",
    "       2322930    -4.205626\n",
    "...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To facilitate working with the final data, we are going to unstack `medicaid_reimbursement_per_enrollee` into a variable called  `medicaid_norm_ndc`\n",
    "- Using `medicaid_reimbursement_per_enrollee`, generate a `DataFrame` where: \n",
    "  - `index` is the two-letter state symbol \n",
    "  - column names are the `NDC` codes \n",
    "- The `DataFrame` should be formatted as in the image below\n",
    "  - Hint: simply unstack the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/unstacked.png\" alt=\"drawing\" style=\"width:900px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the Data \n",
    "\n",
    "* What is the drug with the highest log-normalized ratio in Hawaii?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Investigate the NDC of the product with the highest log-normalized ratio in Hawaii \n",
    "  * What is it used for?\n",
    "\n",
    "* Compare the value of `Units Reimbursed` that product between HI and other states, (take for instance MA, FL, OR and WA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you think for reasons why this product has the highest log-normalized ratio in Hawaii? (Not graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR ANSWER HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find and list all unique `NDC`s for which the difference between the largest and second large log-scale ratio-by-state is at least 10.\n",
    "\n",
    "* For instance:\n",
    "  * The highest log-normalized ratio for `00591289749` (`AZACITIDIN`) is OK where it has a log-normalized ratio of `-1.025642`.\n",
    "  * The second highest log-normalized ratio for `00591289749` is in `GA` where is has a log-normalized ratio of  `-12.623428`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Drug `AZACITIDINE` has a very high normalized UNITS REIMBURSED in OK compared to other states\n",
    "   * Normalized log value is -1.025642 (or a ratio 0.49119167009735065)\n",
    "   * The second highest state has a log value of -12.623428 (0.000158478197834722)\n",
    "* Oklahoma is not a high-incidence state for cancer\n",
    "* Could the following explain what is happening in Oklahoma?\n",
    "  * The following is clinical trial conducted by the University of Oklahoma\n",
    "\n",
    "https://www.centerwatch.com/clinical-trials/listings/92093/acute-myeloid-leukemia-aml-study-asp2215-gilteritinib-by/?&geo_lat=35.4675602&geo_lng=-97.5164276&radius=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
